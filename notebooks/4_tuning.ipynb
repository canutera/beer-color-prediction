{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chosen models\n",
    "- DecisionTree with 2 features, 5 splits and outliers\n",
    "- GradientBoostingRegressor with no outliers, 3 splits and 9 features\n",
    "- Lasso with 5 features, 2 splits and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "> Note: Best features are in order according to importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 rows contain at least one outlier\n",
      "Outlier ratio: 20.67%\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../data/5_selected_Kbest/selected_Kbest.csv').sort_values('job_id').drop('job_id', axis=1)\n",
    "\n",
    "def outliers_index(df, threshold=3):\n",
    "    z_scores = np.abs(stats.zscore(df))\n",
    "    threshold = 3\n",
    "    outliers = df[z_scores > threshold]\n",
    "    \n",
    "    print(f'{len(outliers[outliers.notnull().any(axis=1)])} rows contain at least one outlier')\n",
    "    print('Outlier ratio:', f'{len(outliers[outliers.notnull().any(axis=1)])/len(df):.2%}')\n",
    "    return outliers.notnull().any(axis=1)\n",
    "outliers = outliers_index(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "2 features, 5 splits and outliers\n",
    "> best params: {'max_depth': 1, 'max_leaf_nodes': None, 'min_samples_leaf': 5, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.1, 'splitter': 'best'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9800 candidates, totalling 49000 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 1,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_samples_leaf': 5,\n",
       " 'min_samples_split': 5,\n",
       " 'min_weight_fraction_leaf': 0.1,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_state = 42\n",
    "\n",
    "dt_parameters={\"splitter\": [\"best\",\"random\"],\n",
    "               \"max_depth\": [1,3,5,7,9,11,12],\n",
    "               \"min_samples_leaf\": [5,7,10,15,20],\n",
    "               \"min_samples_split\": [5,10,15,20,30,40,50],\n",
    "               \"min_weight_fraction_leaf\": [0.1,0.2,0.3,0.5],\n",
    "               \"max_leaf_nodes\": [None,10,20,30,40]}\n",
    "\n",
    "dt_tss = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "dt_scaler = StandardScaler()\n",
    "dt_X = dt_scaler.fit_transform(df.iloc[:, :2])\n",
    "dt_scaled = dt_scaler.fit_transform(df)\n",
    "dt_X = dt_scaled[:,:2]\n",
    "dt_y = dt_scaled[:,-1]\n",
    "\n",
    "dt_tuning_model = GridSearchCV(estimator=DecisionTreeRegressor(random_state=random_state),\n",
    "                               param_grid=dt_parameters,\n",
    "                               scoring='neg_mean_squared_error',\n",
    "                               cv=dt_tss, verbose=1, n_jobs=-1)\n",
    "\n",
    "dt_tuning_model.fit(dt_X, dt_y)\n",
    "dt_tuning_model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso\n",
    "5 features, 2 splits and outliers\n",
    "\n",
    "> best params: {'alpha': 0.07, 'max_iter': 100, 'tol': 0.05}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 240 candidates, totalling 480 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.2, 'max_iter': 100, 'tol': 0.01}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_parameters={\"alpha\": [0.005, 0.02, 0.03, 0.05, 0.06, 0.07, 0.1, 0.2, 0.3, 0.5, 0.6, 0.7],\n",
    "                  \"max_iter\": [100, 200, 500, 1000],\n",
    "                  \"tol\": [1e-2, 5e-2, 1e-3, 5e-3, 1e-4]\n",
    "                  }\n",
    "\n",
    "lasso_tss = TimeSeriesSplit(n_splits=2)\n",
    "lasso_scaler = StandardScaler()\n",
    "lasso_scaled = lasso_scaler.fit_transform(df)\n",
    "lasso_X = lasso_scaled[:,:5]\n",
    "lasso_y = lasso_scaled[:,-1]\n",
    "lasso_tuning_model = GridSearchCV(estimator=Lasso(random_state=random_state),\n",
    "                                  param_grid=lasso_parameters,\n",
    "                                  scoring='neg_mean_squared_error',\n",
    "                                  cv=lasso_tss, verbose=1,  n_jobs=-1)\n",
    "lasso_tuning_model.fit(lasso_X, lasso_y)\n",
    "lasso_tuning_model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostedTree\n",
    "no outliers, 3 splits and 9 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 207360 candidates, totalling 622080 fits\n"
     ]
    }
   ],
   "source": [
    "gbt_parameters={\"alpha\": [0.005, 0.03, 0.06, 0.07, 0.1, 0.2,],\n",
    "                \"learning_rate\" : [1e-3,1e-2, 1e-1],\n",
    "                \"n_estimators\": [100, 200, 500, 1000],\n",
    "                \"min_samples_leaf\": [7,10, 20, 30],\n",
    "                \"min_samples_split\": [10,15,20,30,40],\n",
    "                \"min_weight_fraction_leaf\": [0.1,0.2,0.3,0.5,],\n",
    "                \"tol\": [1e-2, 1e-3, 1e-4],\n",
    "                \"max_leaf_nodes\": [None,10,20,30],\n",
    "                \"ccp_alpha\": [2e-3,1e-2,25e-3],\n",
    "                  }\n",
    "\n",
    "gbt_tss = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "gbt_scaler = StandardScaler()\n",
    "gbt_scaled = gbt_scaler.fit_transform(df[~outliers])\n",
    "gbt_X = gbt_scaled[:,:9]\n",
    "gbt_y = gbt_scaled[:, -1]\n",
    "\n",
    "gbt_tuning_model = GridSearchCV(estimator=GradientBoostingRegressor(random_state=random_state),\n",
    "                                param_grid=gbt_parameters,\n",
    "                                scoring='neg_mean_squared_error',\n",
    "                                cv=gbt_tss, verbose=1, n_jobs=-1)\n",
    "\n",
    "gbt_tuning_model.fit(gbt_X, gbt_y)\n",
    "gbt_tuning_model.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
