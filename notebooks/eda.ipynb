{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset and rename columns\n",
    "> Note: **Only AMST** are contained in df. HNK products where filtered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from re import sub\n",
    "\n",
    "def column_name_to_snake_case(s):\n",
    "    s = sub(r\"[\\/( \\- ) ]\", '_', s)\n",
    "    s = sub(r\"(___)|(__)\", '_', s).lower()\n",
    "    return s if s[-1] != '_' else s[:-1]\n",
    "\n",
    "df = pd.read_csv(r'..\\data\\raw\\Heineken - Data Science Use Case.csv', parse_dates=['Date/Time'])\n",
    "df = (df.drop(columns=df.columns[0])\n",
    "        .rename(columns={col:column_name_to_snake_case(col) for col in df.columns[1:]})\n",
    "        .query('product == \"AMST\"')\n",
    "     )\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rows with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls = df[pd.isnull(df).any(axis=1)]\n",
    "print('len nulls:', len(nulls))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing target (color) null values\n",
    "All color null values have no other null value besides the target column.\n",
    "> Note: try to predict these values later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only null that are target \n",
    "target_nulls = nulls.query('color.isnull()')\n",
    "print(target_nulls.drop('color', axis=1).isnull().sum(axis=0))\n",
    "\n",
    "# saving to parse dtypes faster later \n",
    "dtypes = {col:target_nulls[col].dtype for col in target_nulls.columns}\n",
    "\n",
    "target_nulls.to_csv('..\\data\\dropped\\dropped_rows.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check non_target nulls\n",
    "Null values from other column correspond to small percentage of total count of row count.\n",
    "\n",
    "We will use interpolation with KNN to estimate missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_target = nulls.query('color.notnull()')\n",
    "print('non_target nulls len:', len(non_target), '\\n')\n",
    "\n",
    "non_target = (non_target.drop('color', axis=1)\n",
    "                        .isnull().sum(axis=0)[lambda x: x >0]\n",
    "                        .to_frame('null_count'))\n",
    "\n",
    "non_target = (non_target.assign(len_df = len(df))\n",
    "                        .assign(ratio= non_target.null_count/len(df)))\n",
    "\n",
    "print(non_target)\n",
    "\n",
    "\n",
    "# using interpolation to fill NAs on roast amount and ph\n",
    "df = df.assign(**{col:df[col].interpolate(method='nearest') for col in ['roast_amount_kg', 'ph']})\n",
    "print('\\n\\nnull values after interpolation')\n",
    "pd.isnull(df).sum()[lambda x: x > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "selected = (df.select_dtypes(include='number')\n",
    "             .dropna()\n",
    "             .drop(columns=['job_id'])\n",
    "             .dropna()\n",
    "             )\n",
    "feature_cols = selected.columns\n",
    "selected.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check normality of features and target\n",
    "All features were found to be normally distributed besides roast color\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro, kstest\n",
    "\n",
    "print('len features:', len(selected))\n",
    "shapiro_p_value = [shapiro(selected[col].values).pvalue for col in feature_cols]\n",
    "kstest_p_value = [kstest(selected[col].values, 'norm').pvalue for col in feature_cols]\n",
    "\n",
    "normality_tests = pd.DataFrame(\n",
    "    {'columns': feature_cols, 'shapiro_p_value': shapiro_p_value, 'kstest_p_value': kstest_p_value})\n",
    "\n",
    "normality_tests['failed'] = normality_tests.apply(lambda row: 'yes' if row['shapiro_p_value'] > 0.05 or row['kstest_p_value'] > 0.05 else 'no', axis=1)\n",
    "normality_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> note: roast color is constant, so it will be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = selected.drop(columns='roast_color')\n",
    "selected.to_csv('../data/selected/selected.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check normality of target\n",
    "> note: use median for baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapiro_p_value = [shapiro(selected['color'].values).pvalue]\n",
    "kstest_p_value = [kstest(selected['color'].values, 'norm').pvalue]\n",
    "target_normality = pd.DataFrame(\n",
    "    {'columns': ['color'], 'shapiro_p_value': shapiro_p_value, 'kstest_p_value': kstest_p_value})\n",
    "selected[['color']].hist()\n",
    "for i in ['mean', 'median', 'mode']:\n",
    "    print(f'{i}: {getattr(selected.color, i)()}')\n",
    "target_normality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking how null values are positioned in timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['base_amount_kg'] = df['1st_malt_amount_kg'] + df['2nd_malt_amount_kg']\n",
    "# Multiplied by 2 just offset lines a little bit\n",
    "df.roast_amount_kg = df.roast_amount_kg*2\n",
    "df['color (target)'] = df.color\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,5)\n",
    "ax = df.sort_values('date_time').reset_index().plot(x='date_time', y=['ph', 'roast_amount_kg', 'color (target)'])\n",
    "ax.set(title='Position of null values in dataset')\n",
    "\n",
    "# undo changes to dataset\n",
    "df.roast_amount_kg = df.roast_amount_kg/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target box plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df[['color']].boxplot()\n",
    "ax.set(title='Target box plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "\n",
    "#apply the z-score method and get abs \n",
    "z_scores = np.abs(stats.zscore(selected))\n",
    "\n",
    "\n",
    "threshold = 3\n",
    "outliers = selected[z_scores > threshold]\n",
    "print(f'{len(outliers[outliers.notnull().any(axis=1)])} rows contain at least one outlier')\n",
    "outliers = outliers[outliers.notnull().any(axis=1)]\n",
    "print('Outlier ratio:', f'{len(outliers)/len(selected):.2%}')\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_correlation_heatmap(df:pd.DataFrame, corr_method:Literal['pearson', 'spearman', 'kendall']):\n",
    "    plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "    \n",
    "    corr_df = df.dropna().corr(corr_method)\n",
    "    ax = sns.heatmap(corr_df, \n",
    "                    vmin=-1, vmax=1, center=0, \n",
    "                    cmap='bwr', annot=corr_df.values,annot_kws={'fontsize':8})\n",
    "    ax.set(title=f'{corr_method.title()} Correlation plot')\n",
    "    \n",
    "    # absolute correlation \n",
    "    plt.rcParams[\"figure.figsize\"] = (20,5)\n",
    "    corr_abs = (corr_df[['color']].abs()\n",
    "                              .sort_values('color', ascending=False)\n",
    "                              .reset_index(names=['columns'])\n",
    "                              .query('columns != \"color\"'))\n",
    "    ax2  = corr_abs.plot.bar(x='columns', y='color', )\n",
    "    ax2.set(title=f'Absolute {corr_method.title()} Correlation by Feature')\n",
    "    def addlabels(x,y):\n",
    "        for i in range(len(x)):\n",
    "            plt.text(i-0.2,y[i]+0.005,y[i])\n",
    "    addlabels(corr_abs.index, [float('%.3f'%x) for x in corr_abs.color.values])\n",
    "\n",
    "    return ax, ax2\n",
    "\n",
    "plot_correlation_heatmap(df[feature_cols], 'pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### insights:\n",
    "total_cold_wort is highly correlated with:\n",
    "\n",
    "    - extract\n",
    "    - woc_time\n",
    "\n",
    "wk_time and temperature are highly correlated with each other\n",
    "\n",
    "1st and 2nd malt amount are highly correlated with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_heatmap(df[feature_cols], 'spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Insights\n",
    "total_cold_wort has many good correlations with:\n",
    "\n",
    "    - woc_time\n",
    "    - wk_time\n",
    "    - whp_time\n",
    "  \n",
    "1st malt amount has good correlation with:\n",
    "\n",
    "    - wk_temperature\n",
    "    \n",
    "2nd malt amount has good correlation with:\n",
    "\n",
    "    - whp_rest_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "usar time_series_train_test_split\n",
    "\n",
    "treinar com e sem outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
