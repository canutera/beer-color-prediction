{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset and rename columns\n",
    "> Note: **Only AMST** are contained in df. HNK products where filtered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from re import sub\n",
    "\n",
    "def column_name_to_snake_case(s):\n",
    "    # change chars for undescore\n",
    "    s = sub(r\"[\\/( \\- ) ]\", '_', s)\n",
    "    # make undescores unique\n",
    "    s = sub(r\"(___)|(__)\", '_', s).lower()\n",
    "    return s if s[-1] != '_' else s[:-1]\n",
    "\n",
    "df = pd.read_csv(r'..\\data\\raw\\Heineken - Data Science Use Case.csv', parse_dates=['Date/Time'])\n",
    "df = (df.drop(columns=df.columns[0]) # drop csv index\n",
    "        .rename(columns={col:column_name_to_snake_case(col) for col in df.columns[1:]})        \n",
    "     )\n",
    "\n",
    "# saving hnk values to data folder\n",
    "not_amst = df.query('product != \"AMST\"')\n",
    "not_amst.to_csv('../data/dropped/not_amst.csv', index=False)\n",
    "\n",
    "# selecting only amst batches\n",
    "df = df.query('product == \"AMST\"')\n",
    "print(len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rows with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls = df[pd.isnull(df).any(axis=1)]\n",
    "print('len nulls:', len(nulls))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing target (color) null values\n",
    "All color null values have no other null value besides the target column.\n",
    "> Note: try to predict these values later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only null that are target \n",
    "target_nulls = nulls.query('color.isnull()')\n",
    "print(target_nulls.drop('color', axis=1).isnull().sum(axis=0))\n",
    "\n",
    "# saving to parse dtypes faster later \n",
    "dtypes = {col:target_nulls[col].dtype for col in target_nulls.columns}\n",
    "\n",
    "target_nulls.to_csv('..\\data\\dropped\\dropped_rows.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check non_target nulls\n",
    "Null values from other column correspond to small percentage of total count of row count.\n",
    "\n",
    "We will use interpolation with KNN to estimate missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_target = nulls.query('color.notnull()')\n",
    "print('non_target nulls len:', len(non_target), '\\n')\n",
    "\n",
    "non_target = (non_target.drop('color', axis=1)\n",
    "                        .isnull().sum(axis=0)[lambda x: x >0]\n",
    "                        .to_frame('null_count'))\n",
    "\n",
    "non_target = (non_target.assign(len_df = len(df))\n",
    "                        .assign(ratio= non_target.null_count/len(df)))\n",
    "\n",
    "print(non_target)\n",
    "\n",
    "\n",
    "# using interpolation to fill NAs on roast amount and ph\n",
    "df = df.assign(**{col:df[col].interpolate(method='nearest') for col in ['roast_amount_kg', 'ph']})\n",
    "print('\\n\\nnull values after interpolation')\n",
    "pd.isnull(df).sum()[lambda x: x > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "selected = (df.select_dtypes(include='number')\n",
    "              .dropna()\n",
    "             )\n",
    "selected_cols = selected.columns\n",
    "selected.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check normality of features and target\n",
    "All features were found to be normally distributed besides roast color\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.drop(columns=['job_id','color']).hist(bins=20, figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro, kstest\n",
    "\n",
    "print('len features:', len(selected))\n",
    "def check_normality(df:pd.DataFrame, columns:list[str]):\n",
    "    shapiro_p_value = [shapiro(df[col].values).pvalue for col in columns]\n",
    "    kstest_p_value = [kstest(df[col].values, 'norm').pvalue for col in columns]\n",
    "\n",
    "    normality_tests = pd.DataFrame(\n",
    "        {'columns': columns, 'shapiro_p_value': shapiro_p_value, 'kstest_p_value': kstest_p_value})\n",
    "\n",
    "    normality_tests['failed'] = normality_tests.apply(lambda row: 'yes' if row['shapiro_p_value'] > 0.05 or row['kstest_p_value'] > 0.05 else 'no', axis=1)\n",
    "    return normality_tests\n",
    "n = check_normality(selected, selected_cols)\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> note: roast color is constant, so it will be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = selected.drop(columns='roast_color')\n",
    "selected.to_csv('../data/selected/selected.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check normality of target\n",
    "> note: use median for baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_normality = check_normality(selected, ['color'])\n",
    "target_normality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking how null values are positioned in timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['base_amount_kg'] = df['1st_malt_amount_kg'] + df['2nd_malt_amount_kg']\n",
    "# Multiplied by 2 just offset lines a little bit\n",
    "df.roast_amount_kg = df.roast_amount_kg*2\n",
    "df['color (target)'] = df.color\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,5)\n",
    "ax = df.sort_values('date_time').reset_index().plot(x='date_time', y=['ph', 'roast_amount_kg', 'color (target)'])\n",
    "ax.set(title='Position of null values in dataset')\n",
    "\n",
    "# undo changes to dataset\n",
    "df.roast_amount_kg = df.roast_amount_kg/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target box plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df[['color']].boxplot()\n",
    "ax.set(title='Target box plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection\n",
    "> note: check performance with and without outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "\n",
    "#apply the z-score method and get abs \n",
    "z_scores = np.abs(stats.zscore(selected))\n",
    "\n",
    "\n",
    "threshold = 3\n",
    "outliers = selected[z_scores > threshold]\n",
    "print(f'{len(outliers[outliers.notnull().any(axis=1)])} rows contain at least one outlier')\n",
    "outliers = outliers[outliers.notnull().any(axis=1)]\n",
    "print('Outlier ratio:', f'{len(outliers)/len(selected):.2%}')\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "import matplotlib.pyplot as plt\n",
    "def correlation_level(x): \n",
    "    corr = abs(x)\n",
    "    if corr < 0.1: return 'None'\n",
    "    if corr >= 0.1 and corr < 0.3: return 'Weak'\n",
    "    if corr >= 0.3 and corr < 0.6: return 'Moderate'\n",
    "    if corr >= 0.6 and corr < 0.95: return 'Strong'\n",
    "    if x >= 0.95: return 'Perfect'\n",
    "    return 'None'\n",
    "\n",
    "def map_correlation_levels(x, cmap='Dark2'):\n",
    "    levels = ['None', 'Weak', 'Moderate', 'Strong', 'Perfect']\n",
    "    colors = [getattr(plt.cm, cmap)(i) for i in range(len(levels)-1)]\n",
    "    map = dict(zip(levels, colors))\n",
    "    return map.get(x, colors[0])\n",
    "\n",
    "def plot_correlation_heatmap(df:pd.DataFrame, corr_method:Literal['pearson', 'spearman', 'kendall']):\n",
    "    plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "    \n",
    "    corr_df = df.dropna().corr(corr_method)\n",
    "    ax = sns.heatmap(corr_df, \n",
    "                    vmin=-1, vmax=1, center=0, \n",
    "                    cmap='bwr', annot=corr_df.values,annot_kws={'fontsize':8})\n",
    "    ax.set(title=f'{corr_method.title()} Correlation plot')\n",
    "    return ax\n",
    "\n",
    "def plot_correlation_bars(df:pd.DataFrame, column:str,  corr_method:Literal['pearson', 'spearman', 'kendall']):\n",
    "    # absolute correlation \n",
    "    corr_df = df.dropna().corr(corr_method)\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,5)\n",
    "    corr_abs = (corr_df[[column]].assign(abs=corr_df[column].abs())\n",
    "                                 .assign(category=corr_df[column].apply(lambda x: correlation_level(x)))\n",
    "                                 .sort_values('abs', ascending=False)\n",
    "                                 .reset_index(names=['columns'])\n",
    "                                 .query(f'columns != \"{column}\"'))\n",
    "    fig, ax = plt.subplots()\n",
    "    from matplotlib.patches import Patch\n",
    "    color = dict(zip(corr_abs.category.unique(), [map_correlation_levels(x) for x in corr_abs.category.unique()]))\n",
    "    (corr_abs.plot.bar(x='columns', y=column, color=[map_correlation_levels(x) for x in corr_abs.category.values], ax=ax)\n",
    "                  .legend([Patch(facecolor=color[i])for i in color], color))\n",
    "    \n",
    "    ax.set(title=f'{corr_method.title()} Correlation with {column} by column')\n",
    "    def addlabels(x,y):\n",
    "        for i in range(len(x)):\n",
    "            plt.text(i-0.2,y[i]+0.005 if y[i] > 0 else 0.005,y[i])\n",
    "    addlabels(corr_abs.index, [float('%.3f'%x) for x in corr_abs[column].values])\n",
    "\n",
    "    return ax\n",
    "\n",
    "plot_correlation_heatmap(df[selected_cols], 'pearson')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_bars(df[selected_cols], 'color', 'pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_bars(df[selected_cols], 'total_cold_wort', 'pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_bars(df[selected_cols], 'wk_time', 'pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_bars(df[selected_cols], '1st_malt_amount_kg', 'pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### insights:\n",
    "total_cold_wort is highly correlated with:\n",
    "\n",
    "    - extract\n",
    "    - woc_time\n",
    "\n",
    "wk_time and temperature are highly correlated with each other\n",
    "\n",
    "1st and 2nd malt amount are highly correlated with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_heatmap(df[selected_cols],  'spearman')\n",
    "plot_correlation_bars(df[selected_cols], 'color', 'spearman')\n",
    "plot_correlation_bars(df[selected_cols], 'total_cold_wort', 'spearman')\n",
    "plot_correlation_bars(df[selected_cols], '1st_malt_color', 'spearman')\n",
    "plot_correlation_bars(df[selected_cols], '2nd_malt_color', 'spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Insights\n",
    "total_cold_wort has many good correlations with:\n",
    "\n",
    "    - woc_time\n",
    "    - wk_time\n",
    "    - whp_time\n",
    "  \n",
    "1st malt amount has good correlation with:\n",
    "\n",
    "    - wk_temperature\n",
    "    \n",
    "2nd malt amount has good correlation with:\n",
    "\n",
    "    - whp_rest_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "usar time_series_train_test_split\n",
    "\n",
    "treinar com e sem outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
