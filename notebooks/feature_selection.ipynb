{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('../data/4_engineered/engineered_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Literal\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error as mae, mean_squared_error as mse\n",
    "def baseline_dummy_metrics(df:pd.DataFrame, samples:int, strategy:Literal['median','mean']):\n",
    "    '''estimate baseline values for dataset using sklearn dummy regressor\n",
    "    samples is the number of fits to be done\n",
    "\n",
    "    returns\n",
    "    -------\n",
    "    df with r2_score, mean absolute error, mean squared error and std deviations respectively\n",
    "    average for every fit \n",
    "    '''\n",
    "    values = pd.DataFrame()\n",
    "    for i in range(samples):\n",
    "        y = df['color']\n",
    "        X = df.drop('color', axis=1)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=random.randint(1,1000))\n",
    "\n",
    "        dummy_regr = DummyRegressor(strategy=strategy)\n",
    "        dummy_regr.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = dummy_regr.predict(X_test)\n",
    "        values = pd.concat([values, pd.DataFrame.from_records({'r2_score':[r2_score(y_test,y_pred)], 'mae':[mae(y_test,y_pred)], 'mse':[mse(y_test,y_pred)]})], ignore_index=True)\n",
    "    _dict = {}\n",
    "    for col in values.columns:\n",
    "        _dict[col] = values[col].mean()\n",
    "        _dict[f'{col}_std'] = values[col].std()\n",
    "    return pd.DataFrame.from_records([_dict])\n",
    "\n",
    "baseline = baseline_dummy_metrics(df, 10000, 'median')\n",
    "print('Baseline values for metrics')\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Kbest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "X = df.drop('color', axis=1)\n",
    "y = df.color\n",
    "selector = SelectKBest(f_regression, k=len(X.columns))\n",
    "selector.set_output(transform='pandas')\n",
    "X_new = selector.fit_transform(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from tqdm import tqdm\n",
    "random_state = 42\n",
    "decision_tree = DecisionTreeRegressor(random_state=random_state)\n",
    "random_forest = RandomForestRegressor(random_state=random_state)\n",
    "\n",
    "scorers = dict()\n",
    "scorers['r2_score'] = make_scorer(r2_score, greater_is_better=True)\n",
    "scorers['mae'] = make_scorer(mae, greater_is_better=False)\n",
    "scorers['mse'] = make_scorer(r2_score, greater_is_better=False)\n",
    "\n",
    "def search(estimator, range_time_split, range_features,scorers, X, y):\n",
    "    df = pd.DataFrame()\n",
    "    for n_splits in tqdm(range_time_split):\n",
    "        tss = TimeSeriesSplit(n_splits = n_splits)\n",
    "        for n_features in tqdm(range_features):\n",
    "            for scorer in scorers:\n",
    "                scores = cross_val_score(estimator, X.iloc[:, :n_features], y, cv=tss, scoring=scorers[scorer])\n",
    "                new =  pd.DataFrame({'model':[estimator.__class__.__name__], 'n_features':[n_features], 'n_splits':[n_splits], 'scorer':[scorer], 'scores':[scores]})\n",
    "                df = pd.concat([df, new], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "a = pd.concat([search(est, range(2,6), range(2, 16), scorers, X_new,y) for est in [decision_tree, random_forest]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(random_state=random_state)\n",
    "dt.fit(X_new[-5:, :10], y[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.assign(mean_scores=a.scores.apply(np.mean)).reset_index(drop=True)\n",
    "b = b.pivot(index=['model','n_features', 'n_splits'], columns='scorer', values=['mean_scores']).reset_index().sort_values(('mean_scores', 'r2_score')).reset_index(drop=True)\n",
    "b.columns = ['model', 'n_features', 'n_splits', 'mae', 'mse','r2_score']\n",
    "b.sort_values('r2_score', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
